{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7a8b206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# Standard libraries for reading pdf\n",
    "import PyPDF2 as pypdf\n",
    "import PyPDF2\n",
    "import re\n",
    "import requests\n",
    "import io\n",
    "from io import BytesIO\n",
    "import concurrent.futures\n",
    "from itertools import groupby\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "import time\n",
    "import praw\n",
    "\n",
    "# Use open parse for reading the tables\n",
    "import openparse\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Llama libraries for RAG\n",
    "from llama_index.core import (\n",
    "    Document,\n",
    "    Prompt,\n",
    "    VectorStoreIndex,\n",
    "    \n",
    ")\n",
    "from llama_index.core.schema import TextNode, NodeRelationship, RelatedNodeInfo\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "\n",
    "# For the responses\n",
    "from llama_index.core.callbacks import (\n",
    "    CallbackManager,\n",
    "    LlamaDebugHandler,\n",
    "    CBEventType,\n",
    ")\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core.text_splitter import SentenceSplitter\n",
    "from llama_index.core.response_synthesizers import (\n",
    "    ResponseMode,\n",
    "    get_response_synthesizer,\n",
    ")\n",
    "\n",
    "from llama_index.core.retrievers import VectorIndexRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20b210b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard authentication\n",
    "reddit_read_only  = praw.Reddit(\n",
    "    client_id=\"client_id\",\n",
    "    client_secret=\"client_secret\",\n",
    "    user_agent=\"user_agent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03ea9a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display Name: OMSCS\n",
      "Title: Georgia Tech OMS Computer Science\n"
     ]
    }
   ],
   "source": [
    "subreddit = reddit_read_only.subreddit(\"OMSCS\")\n",
    " # Display the name of the Subreddit\n",
    "print(\"Display Name:\", subreddit.display_name)\n",
    " # Display the title of the Subreddit\n",
    "print(\"Title:\", subreddit.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "955e18e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UGGTech\\AppData\\Local\\Temp\\ipykernel_80204\\1678316060.py:2: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  posts = subreddit.top(\"month\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Post Text</th>\n",
       "      <th>ID</th>\n",
       "      <th>Score</th>\n",
       "      <th>Total Comments</th>\n",
       "      <th>Post URL</th>\n",
       "      <th>Flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CS6601 AI: Incomplete grades handed out based ...</td>\n",
       "      <td>The CS6601 Spring 2024 finals had a lot of iss...</td>\n",
       "      <td>1cqqmng</td>\n",
       "      <td>190</td>\n",
       "      <td>73</td>\n",
       "      <td>https://www.reddit.com/r/OMSCS/comments/1cqqmn...</td>\n",
       "      <td>CS 6601 AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A tale of two students - this could apply to s...</td>\n",
       "      <td></td>\n",
       "      <td>1d3lcw2</td>\n",
       "      <td>147</td>\n",
       "      <td>59</td>\n",
       "      <td>https://i.redd.it/797pbb1t8f3d1.png</td>\n",
       "      <td>This is a Meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This has been a humbling experience</td>\n",
       "      <td>I enrolled in this program in Fall 2023. Dropp...</td>\n",
       "      <td>1d6phxr</td>\n",
       "      <td>111</td>\n",
       "      <td>60</td>\n",
       "      <td>https://www.reddit.com/r/OMSCS/comments/1d6phx...</td>\n",
       "      <td>Withdrawal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My Georgia Tech OMSCS Review - Reflections fro...</td>\n",
       "      <td></td>\n",
       "      <td>1d40zmr</td>\n",
       "      <td>111</td>\n",
       "      <td>44</td>\n",
       "      <td>https://www.ddanieltan.com/posts/omscs-review/</td>\n",
       "      <td>I GOT OUT :joyner-shocked:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OMSCS T-Shirt arrived. Have you guys received ...</td>\n",
       "      <td>I entered omscs on fall 2022. It looks good. I...</td>\n",
       "      <td>1d9qcwg</td>\n",
       "      <td>98</td>\n",
       "      <td>33</td>\n",
       "      <td>https://i.redd.it/ypsdclko305d1.jpeg</td>\n",
       "      <td>Social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>switching to OMSCS after core classes at OSU?</td>\n",
       "      <td>I am in a bit of a predicament deciding betwee...</td>\n",
       "      <td>1d5vzdn</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>https://www.reddit.com/r/OMSCS/comments/1d5vzd...</td>\n",
       "      <td>Deferment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Has anyone taken the CS 8001 ODA seminar to pr...</td>\n",
       "      <td>EDIT: i mean cs8001 OLP seminar NOT CS8001 ODA...</td>\n",
       "      <td>1d4i0lt</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.reddit.com/r/OMSCS/comments/1d4i0l...</td>\n",
       "      <td>Courses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>CS/Programming foundations before OMSCS</td>\n",
       "      <td>I’m gearing up for the OMSCS program, but I’m ...</td>\n",
       "      <td>1cy79mr</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>https://www.reddit.com/r/OMSCS/comments/1cy79m...</td>\n",
       "      <td>Admissions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>What are the best courses to list if you have ...</td>\n",
       "      <td>I have graduated with non-stem bachelor degree...</td>\n",
       "      <td>1cur7gg</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>https://www.reddit.com/r/OMSCS/comments/1cur7g...</td>\n",
       "      <td>Courses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>How should I prepare myself for taking Artific...</td>\n",
       "      <td>I do have a CS background but am not very fami...</td>\n",
       "      <td>1dcfu9e</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>https://www.reddit.com/r/OMSCS/comments/1dcfu9...</td>\n",
       "      <td>CS 6601 AI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0   CS6601 AI: Incomplete grades handed out based ...   \n",
       "1   A tale of two students - this could apply to s...   \n",
       "2                 This has been a humbling experience   \n",
       "3   My Georgia Tech OMSCS Review - Reflections fro...   \n",
       "4   OMSCS T-Shirt arrived. Have you guys received ...   \n",
       "..                                                ...   \n",
       "95      switching to OMSCS after core classes at OSU?   \n",
       "96  Has anyone taken the CS 8001 ODA seminar to pr...   \n",
       "97            CS/Programming foundations before OMSCS   \n",
       "98  What are the best courses to list if you have ...   \n",
       "99  How should I prepare myself for taking Artific...   \n",
       "\n",
       "                                            Post Text       ID  Score  \\\n",
       "0   The CS6601 Spring 2024 finals had a lot of iss...  1cqqmng    190   \n",
       "1                                                      1d3lcw2    147   \n",
       "2   I enrolled in this program in Fall 2023. Dropp...  1d6phxr    111   \n",
       "3                                                      1d40zmr    111   \n",
       "4   I entered omscs on fall 2022. It looks good. I...  1d9qcwg     98   \n",
       "..                                                ...      ...    ...   \n",
       "95  I am in a bit of a predicament deciding betwee...  1d5vzdn      8   \n",
       "96  EDIT: i mean cs8001 OLP seminar NOT CS8001 ODA...  1d4i0lt      7   \n",
       "97  I’m gearing up for the OMSCS program, but I’m ...  1cy79mr      6   \n",
       "98  I have graduated with non-stem bachelor degree...  1cur7gg      7   \n",
       "99  I do have a CS background but am not very fami...  1dcfu9e      8   \n",
       "\n",
       "    Total Comments                                           Post URL  \\\n",
       "0               73  https://www.reddit.com/r/OMSCS/comments/1cqqmn...   \n",
       "1               59                https://i.redd.it/797pbb1t8f3d1.png   \n",
       "2               60  https://www.reddit.com/r/OMSCS/comments/1d6phx...   \n",
       "3               44     https://www.ddanieltan.com/posts/omscs-review/   \n",
       "4               33               https://i.redd.it/ypsdclko305d1.jpeg   \n",
       "..             ...                                                ...   \n",
       "95               8  https://www.reddit.com/r/OMSCS/comments/1d5vzd...   \n",
       "96               2  https://www.reddit.com/r/OMSCS/comments/1d4i0l...   \n",
       "97               6  https://www.reddit.com/r/OMSCS/comments/1cy79m...   \n",
       "98               9  https://www.reddit.com/r/OMSCS/comments/1cur7g...   \n",
       "99               9  https://www.reddit.com/r/OMSCS/comments/1dcfu9...   \n",
       "\n",
       "                         Flair  \n",
       "0                   CS 6601 AI  \n",
       "1               This is a Meme  \n",
       "2                   Withdrawal  \n",
       "3   I GOT OUT :joyner-shocked:  \n",
       "4                       Social  \n",
       "..                         ...  \n",
       "95                   Deferment  \n",
       "96                     Courses  \n",
       "97                  Admissions  \n",
       "98                     Courses  \n",
       "99                  CS 6601 AI  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#posts  = subreddit.flair('Registration')\n",
    "posts = subreddit.top(\"month\")\n",
    "# Scraping the top posts of the current month\n",
    " \n",
    "posts_dict = {\"Title\": [], \"Post Text\": [],\n",
    "              \"ID\": [], \"Score\": [],\n",
    "              \"Total Comments\": [], \"Post URL\": [],\n",
    "              \"Flair\": []\n",
    "              }\n",
    " \n",
    "for post in posts:\n",
    "    # Title of each post\n",
    "    posts_dict[\"Title\"].append(post.title)\n",
    "     \n",
    "    # Text inside a post\n",
    "    posts_dict[\"Post Text\"].append(post.selftext)\n",
    "     \n",
    "    # Unique ID of each post\n",
    "    posts_dict[\"ID\"].append(post.id)\n",
    "     \n",
    "    # The score of a post\n",
    "    posts_dict[\"Score\"].append(post.score)\n",
    "     \n",
    "    # Total number of comments inside the post\n",
    "    posts_dict[\"Total Comments\"].append(post.num_comments)\n",
    "     \n",
    "    # URL of each post\n",
    "    posts_dict[\"Post URL\"].append(post.url)\n",
    "    \n",
    "    # Get the flair of the post\n",
    "    posts_dict[\"Flair\"].append(post.link_flair_text)\n",
    "    \n",
    "top_posts = pd.DataFrame(posts_dict)\n",
    "top_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92e7cc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post Text</th>\n",
       "      <th>ID</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6601 was pretty fanatically focused on cheatin...</td>\n",
       "      <td>l3t57oe</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I cannot upvote this enough. I was enrolled in...</td>\n",
       "      <td>l3u6ci6</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Absolutely true. What happened this semester w...</td>\n",
       "      <td>l3ucss8</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Will definitely not be taking this course. Tha...</td>\n",
       "      <td>l3udy36</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You should report this to the faculty with all...</td>\n",
       "      <td>l3ufpil</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Years ago I read the syllabus and chose the GA...</td>\n",
       "      <td>l3ufyw8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Didn't KBAI give everyone 0's on peer reviews ...</td>\n",
       "      <td>l3vfw1u</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I totally feel you. I took this course in 2020...</td>\n",
       "      <td>l3ti579</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>So the students are the beta testers?</td>\n",
       "      <td>l3u921y</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Good to hear that AI is STILL an absolute mess...</td>\n",
       "      <td>l3uwqvp</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I'm still baffled how they had any system at a...</td>\n",
       "      <td>l3v1lom</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This happened to me last semester, same class....</td>\n",
       "      <td>l3v78k6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I took this class Fall 23 and midway through t...</td>\n",
       "      <td>l3viocm</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>All those commenting here should be sure to gi...</td>\n",
       "      <td>l3vpwjm</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>If it consoles anyone, a friend of mine got an...</td>\n",
       "      <td>l3vl0tj</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I took it in the summer of 2022 and I recogniz...</td>\n",
       "      <td>l3wxg6g</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>So OMS CS students are scalable guinea pigs fo...</td>\n",
       "      <td>l3u1nev</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wow. Was thinking about taking AI 6601 next se...</td>\n",
       "      <td>l3vw2fw</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I think the fact that a lot of faculty/student...</td>\n",
       "      <td>l3t5wvw</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Has Joyner weighed in on this issue yet?</td>\n",
       "      <td>l3vauxj</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Those TA's are looking to lose their jobs when...</td>\n",
       "      <td>l3ut4gd</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I would reiterate what [bourbonjunkie51](https...</td>\n",
       "      <td>l45azb5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>If you sincerely believe what you are alleging...</td>\n",
       "      <td>l3vwism</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>As a new student about to start OMSCS, I have...</td>\n",
       "      <td>l3w55h6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I'm 9 classes in and AI is probably my favorit...</td>\n",
       "      <td>l3xaa5x</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Hmm when I took it in 2020 it was a great cour...</td>\n",
       "      <td>l3vyewc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>This seems…terribly unethical. \\n\\nDid they as...</td>\n",
       "      <td>l7229wx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I mean.. what did you think was going to happe...</td>\n",
       "      <td>l3ttc3d</td>\n",
       "      <td>-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Post Text       ID  Score\n",
       "0   6601 was pretty fanatically focused on cheatin...  l3t57oe     89\n",
       "1   I cannot upvote this enough. I was enrolled in...  l3u6ci6     36\n",
       "2   Absolutely true. What happened this semester w...  l3ucss8     26\n",
       "3   Will definitely not be taking this course. Tha...  l3udy36     27\n",
       "4   You should report this to the faculty with all...  l3ufpil     19\n",
       "5   Years ago I read the syllabus and chose the GA...  l3ufyw8     15\n",
       "6   Didn't KBAI give everyone 0's on peer reviews ...  l3vfw1u     12\n",
       "7   I totally feel you. I took this course in 2020...  l3ti579     25\n",
       "8               So the students are the beta testers?  l3u921y     11\n",
       "9   Good to hear that AI is STILL an absolute mess...  l3uwqvp     10\n",
       "10  I'm still baffled how they had any system at a...  l3v1lom     11\n",
       "11  This happened to me last semester, same class....  l3v78k6      9\n",
       "12  I took this class Fall 23 and midway through t...  l3viocm     10\n",
       "13  All those commenting here should be sure to gi...  l3vpwjm     10\n",
       "14  If it consoles anyone, a friend of mine got an...  l3vl0tj     10\n",
       "15  I took it in the summer of 2022 and I recogniz...  l3wxg6g      8\n",
       "16  So OMS CS students are scalable guinea pigs fo...  l3u1nev     14\n",
       "17  Wow. Was thinking about taking AI 6601 next se...  l3vw2fw      7\n",
       "18  I think the fact that a lot of faculty/student...  l3t5wvw     18\n",
       "19           Has Joyner weighed in on this issue yet?  l3vauxj     20\n",
       "20  Those TA's are looking to lose their jobs when...  l3ut4gd      9\n",
       "21  I would reiterate what [bourbonjunkie51](https...  l45azb5      4\n",
       "22  If you sincerely believe what you are alleging...  l3vwism     10\n",
       "23   As a new student about to start OMSCS, I have...  l3w55h6      3\n",
       "24  I'm 9 classes in and AI is probably my favorit...  l3xaa5x      2\n",
       "25  Hmm when I took it in 2020 it was a great cour...  l3vyewc      1\n",
       "26  This seems…terribly unethical. \\n\\nDid they as...  l7229wx      1\n",
       "27  I mean.. what did you think was going to happe...  l3ttc3d    -29"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = reddit_read_only.submission(\"1cqqmng\")\n",
    "\n",
    "comments_dict = {\"Post Text\": [],\n",
    "              \"ID\": [], \"Score\": [],\n",
    "              }\n",
    " \n",
    "for comments in submission.comments:     \n",
    "    # Text inside a post\n",
    "    comments_dict[\"Post Text\"].append(comments.body)\n",
    "     \n",
    "    # Unique ID of each post\n",
    "    comments_dict[\"ID\"].append(comments.id)\n",
    "     \n",
    "    # The score of a post\n",
    "    comments_dict[\"Score\"].append(comments.score)\n",
    "     \n",
    "    \n",
    "comments_df = pd.DataFrame(comments_dict)\n",
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b3c9c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure if we want to deal with the sentiment of the text as well\n",
    "from textblob import TextBlob\n",
    "\n",
    "def compute_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "comments_df['sentiment'] = comments_df.apply(lambda row: compute_sentiment(row['Post Text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "812432a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Post Text': \"6601 was pretty fanatically focused on cheating.\\n\\nCheating is bad and you shouldn't do it, sure, but definitely felt strangely intense in that class.\",\n",
       "  'ID': 'l3t57oe',\n",
       "  'Score': 89,\n",
       "  'sentiment': 0.05000000000000003},\n",
       " {'Post Text': 'I cannot upvote this enough. I was enrolled in this class this past semester, and ended up withdrawing from it during the midterm, purely due to the mismanagement and confusion associated with it. \\n\\nAdditionally, the hyper focus on cheating left me feeling paranoid all the time. Definitely felt like they were constantly out to get me. Since this is my first class, I was afraid the whole program would be like that.',\n",
       "  'ID': 'l3u6ci6',\n",
       "  'Score': 36,\n",
       "  'sentiment': -0.05833333333333332},\n",
       " {'Post Text': 'Absolutely true. What happened this semester was so far past acceptable, I sincerely hope that a further investigation goes into how this class operates, and changes will be made to how it\\'s run. Many reviews and feedback from people who previously survived this class act like it\\'s a badge of honor to get past the horrendous grading and conduct from the staff. IT DOESN\\'T HAVE TO BE THIS WAY. Just because a class was run poorly does not mean that it must always stay that way, or that future students will have to just \"suck it up\" because previous students did. I think this time they have gone too far with the mass incompletes they gave using insufficiently tested anti-cheat software, and then GOING RADIO SILENT PAST REGISTRATION DATES until finally students had to get student affairs involved. This is not the behavior of staff that cares about doing their job - their priorities are obviously elsewhere, namely vacation / research data.\\n\\nAs an aside, I wish my university job was as lenient to me about drawing salary \"teaching\" a class, and all I have to do is delegate everything to TAs and only post maybe one or two class announcements the entire time. Admins would be on our asses so hard if we behaved the way Thad did. I\\'m shocked a top rated uni like Georgia Tech is okay with this.',\n",
       "  'ID': 'l3ucss8',\n",
       "  'Score': 26,\n",
       "  'sentiment': 0.03046875},\n",
       " {'Post Text': 'Will definitely not be taking this course. Thank you for the heads up. I’ll do KBAI instead.',\n",
       "  'ID': 'l3udy36',\n",
       "  'Score': 27,\n",
       "  'sentiment': 0.0},\n",
       " {'Post Text': 'You should report this to the faculty with all the points you stated.',\n",
       "  'ID': 'l3ufpil',\n",
       "  'Score': 19,\n",
       "  'sentiment': 0.0},\n",
       " {'Post Text': 'Years ago I read the syllabus and chose the GA path over AI . Seems like a wise choice hehe, at least GA you don’t have to deal with all the bullshit related to the projects',\n",
       "  'ID': 'l3ufyw8',\n",
       "  'Score': 15,\n",
       "  'sentiment': 0.13333333333333333},\n",
       " {'Post Text': \"Didn't KBAI give everyone 0's on peer reviews (of all things) due to a faulty AI plagiarism detector? Some courses are going too far with this.\",\n",
       "  'ID': 'l3vfw1u',\n",
       "  'Score': 12,\n",
       "  'sentiment': -0.012499999999999997},\n",
       " {'Post Text': 'I totally feel you. I took this course in 2020, and all the feedback back then were the exam questions are not well thought of and led to ambiguity and issue with grading. They also had a question that was sexist and insensitive. Given the attitude of the TAs at the end of the course back then, it’s not surprising to see this course has not only not improved, but gotten worse over time.\\n\\nIt’s both unprofessional and unethical to use students as Guinea pigs and pass on unnecessary burden and stress to students. The school’s institutional review board should be aware.',\n",
       "  'ID': 'l3ti579',\n",
       "  'Score': 25,\n",
       "  'sentiment': -0.11249999999999999},\n",
       " {'Post Text': 'So the students are the beta testers?',\n",
       "  'ID': 'l3u921y',\n",
       "  'Score': 11,\n",
       "  'sentiment': 0.0},\n",
       " {'Post Text': 'Good to hear that AI is STILL an absolute mess. You’re not alone I 100% understand what you’re going through.',\n",
       "  'ID': 'l3uwqvp',\n",
       "  'Score': 10,\n",
       "  'sentiment': 0.2416666666666666},\n",
       " {'Post Text': 'I\\'m still baffled how they had any system at all for cheating on the multiple choice/number fill in exam. And even if something \"flagged\" I would say in no way would could a similar enough multiple choice test to someone else be grounds to pursue academic dishonesty.',\n",
       "  'ID': 'l3v1lom',\n",
       "  'Score': 11,\n",
       "  'sentiment': 0.0},\n",
       " {'Post Text': \"This happened to me last semester, same class. I was flagged on a section that entirely matched another student's strangely incorrect answers. And yet... I scored a 100% on that section. I don't want to assume anything but it definitely felt like they were out to catch people and caused so much unnecessary stress during the holidays. Its sad too cause that was probably my favorite course content wise and I thought I learned the most from it compared to every other class so far.\",\n",
       "  'ID': 'l3v78k6',\n",
       "  'Score': 9,\n",
       "  'sentiment': 0.06041666666666667},\n",
       " {'Post Text': 'I took this class Fall 23 and midway through the final exam week they sent out a notice saying my midterm exam was flagged for potential academic misconduct.  Ultimately they dropped the case against me about a week later because they were satisfied with the scratch work I submitted with the exam.  That being said, it caused a lot of undue stress on me in the middle of taking the final.  This was the only class I took in the whole program where I experienced anything like this.\\n\\nOverall, I really enjoyed the content of the class and I learned a lot.  I do have to say though that how the exams are administered and the amount of stress I experienced related to the above incident left a bad taste in my mouth.',\n",
       "  'ID': 'l3viocm',\n",
       "  'Score': 10,\n",
       "  'sentiment': 0.11666666666666667},\n",
       " {'Post Text': 'All those commenting here should be sure to give bad reviews to the course staff in the course evaluation. Maybe that could help for the future.',\n",
       "  'ID': 'l3vpwjm',\n",
       "  'Score': 10,\n",
       "  'sentiment': -0.06666666666666661},\n",
       " {'Post Text': 'If it consoles anyone, a friend of mine got an I because in his last assignment there was an OSI case. When the case resolved, it took whole 2 months, mind you, 2 months, for the professor to come back and correct the grade.\\n\\nHe is simply lazy, I think.',\n",
       "  'ID': 'l3vl0tj',\n",
       "  'Score': 10,\n",
       "  'sentiment': -0.012499999999999997},\n",
       " {'Post Text': 'I took it in the summer of 2022 and I recognize some of the issues that have been brought up concerning spring of 2024, but it was nowhere close to what has been described. To learn that the class was used as guinea pigs for a cheating detection system is negligent and should have repercussions. At best it should have been used in a sandbox to compare to the existing system. When then I would imagine this should require consent.',\n",
       "  'ID': 'l3wxg6g',\n",
       "  'Score': 8,\n",
       "  'sentiment': 1.0},\n",
       " {'Post Text': 'So OMS CS students are scalable guinea pigs for testing research ideas about cheating? Who would have thought?',\n",
       "  'ID': 'l3u1nev',\n",
       "  'Score': 14,\n",
       "  'sentiment': 0.0},\n",
       " {'Post Text': \"Wow. Was thinking about taking AI 6601 next semester. I've read about the difficulty and didn't mind as long as I was learning something. But all this is just unnecessary stress along with the disastrous exam. I thought OMSCS would try to run their courses better. Definitely steering clear for now.\",\n",
       "  'ID': 'l3vw2fw',\n",
       "  'Score': 7,\n",
       "  'sentiment': -0.05625},\n",
       " {'Post Text': 'I think the fact that a lot of faculty/students in this program are using its unique properties to develop potentially innovative and useful anti-cheat methods is really cool. However I agree with OP that this needs to be balanced with not interfering with the student experience.',\n",
       "  'ID': 'l3t5wvw',\n",
       "  'Score': 18,\n",
       "  'sentiment': 0.38125},\n",
       " {'Post Text': 'Has Joyner weighed in on this issue yet?',\n",
       "  'ID': 'l3vauxj',\n",
       "  'Score': 20,\n",
       "  'sentiment': 0.0},\n",
       " {'Post Text': \"Those TA's are looking to lose their jobs when the enrollment numbers drop. Why would anyone take a class with this kind of chaos?\",\n",
       "  'ID': 'l3ut4gd',\n",
       "  'Score': 9,\n",
       "  'sentiment': 0.6},\n",
       " {'Post Text': 'I would reiterate what [bourbonjunkie51](https://www.reddit.com/user/bourbonjunkie51/) said go to the dean or the program coordinator and bring your case. \\n\\nWhen my Dad was in medical school a guest lecturer who was researching topics related to diabetes came to teach the class about diabetes for a few months. Nearly half way through his time teaching he had focused almost exclusively on sharing about his research instead of teaching about diabetes. The class had learned almost nothing about diagnosing, treating, or preventing diabetes. So he went to the dean and after listening to my Dad for a few minutes he said \"That lecturer will never teach at this University again!\". My Dad was shocked and had just wanted the dean to talk with him and direct him back towards the topic he was paid to teach. \\n\\nBeing excited about your research isn\\'t a valid excuse to disable your students from learning what they are supposed to be learning.',\n",
       "  'ID': 'l45azb5',\n",
       "  'Score': 4,\n",
       "  'sentiment': -0.08916666666666666},\n",
       " {'Post Text': 'If you sincerely believe what you are alleging here (and can back it up) I would recommend going to someone at a Dean level, and not just posting to Reddit\\n\\nAnd if you’ve already done that and said so in your post, sorry, it’s a whole lot of words and I’m not reading them all lol',\n",
       "  'ID': 'l3vwism',\n",
       "  'Score': 10,\n",
       "  'sentiment': 0.2},\n",
       " {'Post Text': ' As a new student about to start OMSCS, I have a question. Why would a final exam be checked for plagiarism? Aren’t exams proctored/monitored, preventing people from looking up their phones? Also, I would assume online exams would have systems that prevent people from opening other tabs or copying+pasting. So I’m really surprised that a final exam would be checked for plagiarism.\\n\\nIf a current student could provide some insight on why this would happen, it would be very helpful.',\n",
       "  'ID': 'l3w55h6',\n",
       "  'Score': 3,\n",
       "  'sentiment': 0.04448051948051949},\n",
       " {'Post Text': 'I\\'m 9 classes in and AI is probably my favorite class in the program, but damn I feel your pain. Junior year of undergrad, I was given an \"I\" for a class for 4 weeks over a MATLAB assignment worth only 1.25% of my overall grade as my code was similar to another students. I obviously didn\\'t cheat and had no idea who the other student was. Eventually they dismissed it, but that was some of the most stressful weeks of my life.',\n",
       "  'ID': 'l3xaa5x',\n",
       "  'Score': 2,\n",
       "  'sentiment': 0.146875},\n",
       " {'Post Text': 'Hmm when I took it in 2020 it was a great course with fantastic TAs and well designed exams (tho still have to check the corrections during the exam). Did something changed drastically in recent semesters?',\n",
       "  'ID': 'l3vyewc',\n",
       "  'Score': 1,\n",
       "  'sentiment': 0.4000000000000001},\n",
       " {'Post Text': 'This seems…terribly unethical.\\xa0\\n\\nDid they ask you all to consent to be included in what was effectively a human participants research study prior to the start of the semester? I know faculty often have a hard time grokking the equivalence of “students” with “human beings”, but that’s what students are. If you consented, and the information provided in the consent form clearly called out the potential delay in receiving \\xa0your grades, and they obtained (assuming this is possible) an exemption allowing them to use the “I” grade as a placeholder, Ok. Still not great, but at least they’d be following the rules. But if not….\\n\\nThis is, frankly, deeply unsettling and pretty upsetting. It may be time to rethink that yearly alumni contribution if this is what the money is going towards…',\n",
       "  'ID': 'l7229wx',\n",
       "  'Score': 1,\n",
       "  'sentiment': -0.09513888888888888},\n",
       " {'Post Text': 'I mean.. what did you think was going to happen? It needs to be cheap and scalable.',\n",
       "  'ID': 'l3ttc3d',\n",
       "  'Score': -29,\n",
       "  'sentiment': 0.04375000000000001}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = comments_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f24af9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UGGTech\\anaconda3\\envs\\RAG_Env\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from ggml-model-Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = model\n",
      "llama_model_loader: - kv   2:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   6:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   7:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  12:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,128256]  = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128001\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.unknown_token_id u32              = 128002\n",
      "llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: missing pre-tokenizer type, using: 'default'\n",
      "llm_load_vocab:                                             \n",
      "llm_load_vocab: ************************************        \n",
      "llm_load_vocab: GENERATION QUALITY WILL BE DEGRADED!        \n",
      "llm_load_vocab: CONSIDER REGENERATING THE MODEL             \n",
      "llm_load_vocab: ************************************        \n",
      "llm_load_vocab:                                             \n",
      "llm_load_vocab: special tokens definition check successful ( 256/128256 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 4.58 GiB (4.89 BPW) \n",
      "llm_load_print_meta: general.name     = model\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
      "llm_load_print_meta: UNK token        = 128002 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '!'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
      "llm_load_tensors:        CPU buffer size =  4685.30 MiB\n",
      "........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 500000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   512.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   296.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'model', 'general.architecture': 'llama', 'llama.block_count': '32', 'llama.vocab_size': '128256', 'llama.context_length': '8192', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '128001', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.model': 'gpt2', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.ggml.unknown_token_id': '128002', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\"}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
      "\n",
      "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "' }}\n",
      "Using chat eos_token: <|end_of_text|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "text_embedding_model = \"thenlper/gte-base\"\n",
    "# Instantiate LLM and embedding model\n",
    "embed_model = HuggingFaceEmbedding(model_name=text_embedding_model)\n",
    "#model = 'llama-2-7b-chat.Q4_K_M.gguf'\n",
    "model = 'ggml-model-Q4_K_M.gguf'\n",
    "\n",
    "llm = LlamaCPP(model_path=model, temperature=0, max_new_tokens=256, context_window=4096, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "929460ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UGGTech\\AppData\\Local\\Temp\\ipykernel_80204\\3092009722.py:7: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])\n",
    "text_splitter = SentenceSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=256\n",
    ")\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    callback_manager=callback_manager,\n",
    "    llm=llm,\n",
    "    embed_model=embed_model,\n",
    "    text_splitter=text_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ad91c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text nodes with metadata added to the vector store successfully!\n",
      "**********\n",
      "Trace: index_construction\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "text_nodes = []\n",
    "for entry in data_dict:\n",
    "    text_node = TextNode(\n",
    "        text=entry['Post Text'],\n",
    "        id_=entry['ID'],\n",
    "        metadata={\n",
    "            'score': entry['Score'],\n",
    "            'sentiment': entry['sentiment']\n",
    "        }\n",
    "    )\n",
    "    text_nodes.append(text_node)\n",
    "\n",
    "print(\"Text nodes with metadata added to the vector store successfully!\")\n",
    "\n",
    "index = VectorStoreIndex(\n",
    "    text_nodes,\n",
    "    service_context=service_context,\n",
    "    embed_model=embed_model,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71670e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 78.1 ms\n",
      "Wall time: 313 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Query engine with streaming response and top 1 document filter for efficiency\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=ResponseMode.COMPACT,\n",
    "    service_context=service_context,\n",
    "    streaming=True\n",
    ")\n",
    "query_engine = index.as_query_engine(\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    similarity_top_k=1,\n",
    "    streaming=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a31b7d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The class CS6001 was used as guinea pigs for a cheating detection system in summer of 2022 which is negligent and should have repercussions. It would be better to take the class in a sandbox to compare with existing systems and require consent. \n",
      "It's not clear whether the class is worth taking or not based on this information."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   22047.00 ms\n",
      "llama_print_timings:      sample time =      55.71 ms /    69 runs   (    0.81 ms per token,  1238.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.81 ms /     9 tokens (  113.98 ms per token,     8.77 tokens per second)\n",
      "llama_print_timings:        eval time =   18355.46 ms /    68 runs   (  269.93 ms per token,     3.70 tokens per second)\n",
      "llama_print_timings:       total time =   20126.14 ms /    77 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 25.8 s\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = query_engine.query(\"Summerize the class CS6001 and if it worth taking\")\n",
    "response.print_response_stream()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
