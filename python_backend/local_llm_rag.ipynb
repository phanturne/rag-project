{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from openai import OpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from llama_parse import LlamaParse\n",
    "import nest_asyncio\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secret:\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = \n",
    "os.environ['OPENAI_API_KEY'] = \n",
    "os.environ['LLAMA_CLOUD_API_KEY'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id cac11eca-fa9d-40ca-8237-e768bc5a9ea7\n"
     ]
    }
   ],
   "source": [
    "# parse the document, save as a md file.\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "parser = LlamaParse(\n",
    "    #api_key=,  # can also be set in your env as LLAMA_CLOUD_API_KEY\n",
    "    result_type=\"markdown\",  # \"markdown\" and \"text\" are available\n",
    "    num_workers=4,  # if multiple files passed, split in `num_workers` API calls\n",
    "    verbose=True,\n",
    "    language=\"en\",  # Optionally you can define a language, default=en\n",
    ")\n",
    "\n",
    "# sync\n",
    "documents = parser.load_data(\"Orientation Documents-Spring 2024 Orientation Document.pdf\")\n",
    "documents\n",
    "\n",
    "# save the parsed data\n",
    "parse_path = \"parsed_data.md\"\n",
    "with open(parse_path, \"w\") as f:\n",
    "    f.write(documents[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the parsed data\n",
    "document_path = \"parsed_data.md\"\n",
    "loader = UnstructuredMarkdownLoader(document_path)\n",
    "loaded_documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the parse data into chunks, the chunk size is 512 characters\n",
    "# This parameter is very important, it will affect the performance of the model\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=20)\n",
    "splits = text_splitter.split_documents(loaded_documents)\n",
    "\n",
    "# Embed\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The program mentioned involves selecting a concentration or specialization for your current program of study. It is expected that students in this program are proficient in multiple programming languages and have taken advanced topics like Advanced OS, Networking, Theory, and/or Algorithms. More information can be found on the program's website.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### RETRIEVAL and GENERATION using ChatGPT 3.5####\n",
    "\n",
    "# pull a generic prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain_ChatGPT = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Question\n",
    "rag_chain_ChatGPT.invoke(\"What is this program?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RETRIEVAL and GENERATION using Llama###\n",
    "\n",
    "# The Llama model is hosted locally and can be accessed via the OpenAI API\n",
    "\n",
    "template = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Don't state your role and task. Avoid using preface like \"According to the provided context\".\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "\n",
    "local_prompt = ChatPromptTemplate.from_template(template)\n",
    "local_prompt\n",
    "\n",
    "\n",
    "#local_prompt = prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Define the function to interact with the local LLM server\n",
    "def local_llm(prompt_text):\n",
    "    # Point to the local server\n",
    "    client = OpenAI(base_url=\"http://192.168.68.78:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": str(prompt_text)}\n",
    "    ],\n",
    "    temperature=0.8,\n",
    "    )\n",
    "    return str(completion.choices[0].message.content)\n",
    "\n",
    "# Update the chain to use the local LLM server\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | local_prompt\n",
    "    | local_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>qns_no</th>\n",
       "      <th>qns</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Student Onboarding/GT Email Account</td>\n",
       "      <td>1</td>\n",
       "      <td>Where do I send my official transcript(s) and ...</td>\n",
       "      <td>Send your final official transcript(s) and oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Student Onboarding/GT Email Account</td>\n",
       "      <td>2</td>\n",
       "      <td>What happens if I do not submit my official tr...</td>\n",
       "      <td>If you are a new student starting Spring 2024,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Student Onboarding/GT Email Account</td>\n",
       "      <td>3</td>\n",
       "      <td>Is there an orientation for the OMSCS program?</td>\n",
       "      <td>Since this is an online program, we do not hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Student Onboarding/GT Email Account</td>\n",
       "      <td>4</td>\n",
       "      <td>What are the expectations regarding my GT emai...</td>\n",
       "      <td>The Institute, as well as the department, will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Student Onboarding/GT Email Account</td>\n",
       "      <td>5</td>\n",
       "      <td>How can I access my GT email account?</td>\n",
       "      <td>Please visit this website for information on h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Graduation</td>\n",
       "      <td>13</td>\n",
       "      <td>Is it possible to graduate with honors/distinc...</td>\n",
       "      <td>Graduating with distinction/honors is not avai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Graduation</td>\n",
       "      <td>14</td>\n",
       "      <td>Can I continue taking OMSCS courses after I gr...</td>\n",
       "      <td>It is possible for students to continue taking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Graduation</td>\n",
       "      <td>15</td>\n",
       "      <td>Can I continue being a TA after I graduate fro...</td>\n",
       "      <td>This is possible, but it is more complicated t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Graduation</td>\n",
       "      <td>16</td>\n",
       "      <td>What technology-related services will I retain...</td>\n",
       "      <td>Please visit https://gatech.service-now.com/ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Graduation</td>\n",
       "      <td>17</td>\n",
       "      <td>How can I request a degree verification from t...</td>\n",
       "      <td>Please visit the Registrar’s website for infor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    category  qns_no  \\\n",
       "0    New Student Onboarding/GT Email Account       1   \n",
       "1    New Student Onboarding/GT Email Account       2   \n",
       "2    New Student Onboarding/GT Email Account       3   \n",
       "3    New Student Onboarding/GT Email Account       4   \n",
       "4    New Student Onboarding/GT Email Account       5   \n",
       "..                                       ...     ...   \n",
       "153                               Graduation      13   \n",
       "154                               Graduation      14   \n",
       "155                               Graduation      15   \n",
       "156                               Graduation      16   \n",
       "157                               Graduation      17   \n",
       "\n",
       "                                                   qns  \\\n",
       "0    Where do I send my official transcript(s) and ...   \n",
       "1    What happens if I do not submit my official tr...   \n",
       "2       Is there an orientation for the OMSCS program?   \n",
       "3    What are the expectations regarding my GT emai...   \n",
       "4                How can I access my GT email account?   \n",
       "..                                                 ...   \n",
       "153  Is it possible to graduate with honors/distinc...   \n",
       "154  Can I continue taking OMSCS courses after I gr...   \n",
       "155  Can I continue being a TA after I graduate fro...   \n",
       "156  What technology-related services will I retain...   \n",
       "157  How can I request a degree verification from t...   \n",
       "\n",
       "                                                   ans  \n",
       "0    Send your final official transcript(s) and oth...  \n",
       "1    If you are a new student starting Spring 2024,...  \n",
       "2    Since this is an online program, we do not hav...  \n",
       "3    The Institute, as well as the department, will...  \n",
       "4    Please visit this website for information on h...  \n",
       "..                                                 ...  \n",
       "153  Graduating with distinction/honors is not avai...  \n",
       "154  It is possible for students to continue taking...  \n",
       "155  This is possible, but it is more complicated t...  \n",
       "156  Please visit https://gatech.service-now.com/ho...  \n",
       "157  Please visit the Registrar’s website for infor...  \n",
       "\n",
       "[158 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load evaluation questions\n",
    "questions = pd.read_csv(\"faq_output.csv\")\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'How long should I expect to wait before I receive a wait list notification?', 'answer': 'There is no specific amount of time as to when students will receive a wait list notification, as we unfortunately\\ncannot guarantee that everyone on every wait list will get into the course. As stated previously, some courses are\\nunable to scale above a certain maximum while still providing an effective learning experience for students.\\nPlease note that the advisors are unable to determine/predict which courses will have more seats added.\\nTherefore, please be sure to monitor your email account carefully and frequently, including your spam folder, in\\ncase you receive a wait list notification.'}\n"
     ]
    }
   ],
   "source": [
    "# This is a random question generator\n",
    "def get_sample_questions():\n",
    "    random_question = questions.sample().iloc[0]\n",
    "    return {'question':random_question.qns, 'answer':random_question.ans}\n",
    "\n",
    "print(get_sample_questions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question is: If I am not sure that I will meet the degree requirements by the end of the term, am I still permitted to\n",
      "\n",
      "chatGPT answer: If you do not meet your foundational requirement by the designated deadline, your graduation application may be inactivated. In this case, you would need to enroll in a future term to fulfill the degree requirements.\n",
      "Time to invoke chatGPT: 1.17 seconds\n",
      "\n",
      "Local LLAMA answer: No, you are not permitted to attend the commencement ceremony if you're unsure about meeting degree requirements. You can still attend, but you'll need to enroll in a future term to fulfill the degree requirements.\n",
      "Time to invoke local LLAMA: 1.42 seconds\n",
      "\n",
      "The official answer is: attend the commencement ceremony?\n",
      "Since grades are not finalized until after the commencement ceremony, there have been times when students\n",
      "Click here to return to Table of Contents\n",
      "34\n",
      "\n",
      "\n",
      "have attended the commencement ceremony but unfortunately did not earn the grade(s) they needed. In this\n",
      "case, the student would need to enroll in a future term in order to fulfill the degree requirements.\n",
      "Therefore, if you are a degree candidate and have followed the steps on the Commencement Office’s website to\n",
      "attend the ceremony, you should be eligible to attend, even if you are not sure you will obtain the grade(s) you\n",
      "need. Please feel free to contact the Commencement Office directly if you have additional questions regarding\n",
      "this. As a reminder, the Commencement Office’s contact information can be found online.\n"
     ]
    }
   ],
   "source": [
    "# Get sample questions and invoke the chains once\n",
    "\n",
    "start_time = time.time()\n",
    "q_and_a = get_sample_questions()\n",
    "print('The question is:', q_and_a.get('question'))\n",
    "print()\n",
    "\n",
    "# Invoke chatGPT\n",
    "start_time = time.time()\n",
    "print('chatGPT answer:', rag_chain_ChatGPT.invoke(q_and_a.get('question')))\n",
    "print('Time to invoke chatGPT:', round(time.time() - start_time,2),'seconds')\n",
    "print()\n",
    "\n",
    "# Invoke local LLAMA\n",
    "start_time = time.time()\n",
    "print('Local LLAMA answer:', rag_chain.invoke(q_and_a.get('question')))\n",
    "print('Time to invoke local LLAMA:', round(time.time() - start_time,2),'seconds')\n",
    "print()\n",
    "\n",
    "print('The official answer is:', q_and_a.get('answer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating answer for question 0.\n",
      "Finished generating answer for question 1.\n",
      "Finished generating answer for question 2.\n",
      "Finished generating answer for question 3.\n",
      "Finished generating answer for question 4.\n",
      "Finished generating answer for question 5.\n",
      "Finished generating answer for question 6.\n",
      "Finished generating answer for question 7.\n",
      "Finished generating answer for question 8.\n",
      "Finished generating answer for question 9.\n",
      "Finished generating answer for question 10.\n",
      "Finished generating answer for question 11.\n",
      "Finished generating answer for question 12.\n",
      "Finished generating answer for question 13.\n",
      "Finished generating answer for question 14.\n",
      "Finished generating answer for question 15.\n",
      "Finished generating answer for question 16.\n",
      "Finished generating answer for question 17.\n",
      "Finished generating answer for question 18.\n",
      "Finished generating answer for question 19.\n",
      "Finished generating answer for question 20.\n",
      "Finished generating answer for question 21.\n",
      "Finished generating answer for question 22.\n",
      "Finished generating answer for question 23.\n",
      "Finished generating answer for question 24.\n",
      "Finished generating answer for question 25.\n",
      "Finished generating answer for question 26.\n",
      "Finished generating answer for question 27.\n",
      "Finished generating answer for question 28.\n",
      "Finished generating answer for question 29.\n",
      "Finished generating answer for question 30.\n",
      "Finished generating answer for question 31.\n",
      "Finished generating answer for question 32.\n",
      "Finished generating answer for question 33.\n",
      "Finished generating answer for question 34.\n",
      "Finished generating answer for question 35.\n",
      "Finished generating answer for question 36.\n",
      "Finished generating answer for question 37.\n",
      "Finished generating answer for question 38.\n",
      "Finished generating answer for question 39.\n",
      "Finished generating answer for question 40.\n",
      "Finished generating answer for question 41.\n",
      "Finished generating answer for question 42.\n",
      "Finished generating answer for question 43.\n",
      "Finished generating answer for question 44.\n",
      "Finished generating answer for question 45.\n",
      "Finished generating answer for question 46.\n",
      "Finished generating answer for question 47.\n",
      "Finished generating answer for question 48.\n",
      "Finished generating answer for question 49.\n",
      "Finished generating answer for question 50.\n",
      "Finished generating answer for question 51.\n",
      "Finished generating answer for question 52.\n",
      "Finished generating answer for question 53.\n",
      "Finished generating answer for question 54.\n",
      "Finished generating answer for question 55.\n",
      "Finished generating answer for question 56.\n",
      "Finished generating answer for question 57.\n",
      "Finished generating answer for question 58.\n",
      "Finished generating answer for question 59.\n",
      "Finished generating answer for question 60.\n",
      "Finished generating answer for question 61.\n",
      "Finished generating answer for question 62.\n",
      "Finished generating answer for question 63.\n",
      "Finished generating answer for question 64.\n",
      "Finished generating answer for question 65.\n",
      "Finished generating answer for question 66.\n",
      "Finished generating answer for question 67.\n",
      "Finished generating answer for question 68.\n",
      "Finished generating answer for question 69.\n",
      "Finished generating answer for question 70.\n",
      "Finished generating answer for question 71.\n",
      "Finished generating answer for question 72.\n",
      "Finished generating answer for question 73.\n",
      "Finished generating answer for question 74.\n",
      "Finished generating answer for question 75.\n",
      "Finished generating answer for question 76.\n",
      "Finished generating answer for question 77.\n",
      "Finished generating answer for question 78.\n",
      "Finished generating answer for question 79.\n",
      "Finished generating answer for question 80.\n",
      "Finished generating answer for question 81.\n",
      "Finished generating answer for question 82.\n",
      "Finished generating answer for question 83.\n",
      "Finished generating answer for question 84.\n",
      "Finished generating answer for question 85.\n",
      "Finished generating answer for question 86.\n",
      "Finished generating answer for question 87.\n",
      "Finished generating answer for question 88.\n",
      "Finished generating answer for question 89.\n",
      "Finished generating answer for question 90.\n",
      "Finished generating answer for question 91.\n",
      "Finished generating answer for question 92.\n",
      "Finished generating answer for question 93.\n",
      "Finished generating answer for question 94.\n",
      "Finished generating answer for question 95.\n",
      "Finished generating answer for question 96.\n",
      "Finished generating answer for question 97.\n",
      "Finished generating answer for question 98.\n",
      "Finished generating answer for question 99.\n",
      "Finished generating answer for question 100.\n",
      "Finished generating answer for question 101.\n",
      "Finished generating answer for question 102.\n",
      "Finished generating answer for question 103.\n",
      "Finished generating answer for question 104.\n",
      "Finished generating answer for question 105.\n",
      "Finished generating answer for question 106.\n",
      "Finished generating answer for question 107.\n",
      "Finished generating answer for question 108.\n",
      "Finished generating answer for question 109.\n",
      "Finished generating answer for question 110.\n",
      "Finished generating answer for question 111.\n",
      "Finished generating answer for question 112.\n",
      "Finished generating answer for question 113.\n",
      "Finished generating answer for question 114.\n",
      "Finished generating answer for question 115.\n",
      "Finished generating answer for question 116.\n",
      "Finished generating answer for question 117.\n",
      "Finished generating answer for question 118.\n",
      "Finished generating answer for question 119.\n",
      "Finished generating answer for question 120.\n",
      "Finished generating answer for question 121.\n",
      "Finished generating answer for question 122.\n",
      "Finished generating answer for question 123.\n",
      "Finished generating answer for question 124.\n",
      "Finished generating answer for question 125.\n",
      "Finished generating answer for question 126.\n",
      "Finished generating answer for question 127.\n",
      "Finished generating answer for question 128.\n",
      "Finished generating answer for question 129.\n",
      "Finished generating answer for question 130.\n",
      "Finished generating answer for question 131.\n",
      "Finished generating answer for question 132.\n",
      "Finished generating answer for question 133.\n",
      "Finished generating answer for question 134.\n",
      "Finished generating answer for question 135.\n",
      "Finished generating answer for question 136.\n",
      "Finished generating answer for question 137.\n",
      "Finished generating answer for question 138.\n",
      "Finished generating answer for question 139.\n",
      "Finished generating answer for question 140.\n",
      "Finished generating answer for question 141.\n",
      "Finished generating answer for question 142.\n",
      "Finished generating answer for question 143.\n",
      "Finished generating answer for question 144.\n",
      "Finished generating answer for question 145.\n",
      "Finished generating answer for question 146.\n",
      "Finished generating answer for question 147.\n",
      "Finished generating answer for question 148.\n",
      "Finished generating answer for question 149.\n",
      "Finished generating answer for question 150.\n",
      "Finished generating answer for question 151.\n",
      "Finished generating answer for question 152.\n",
      "Finished generating answer for question 153.\n",
      "Finished generating answer for question 154.\n",
      "Finished generating answer for question 155.\n",
      "Finished generating answer for question 156.\n",
      "Finished generating answer for question 157.\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "with open('faq_output_with_answers_compare_new.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Question', 'Answer', 'chatGPT_answer', 'Local_LLAMA_answer','chat_gpt_time','local_llama_time'])\n",
    "\n",
    "    for row in questions.iterrows():\n",
    "        question = row[1].qns\n",
    "        answer = row[1].ans\n",
    "        start_time = time.time()\n",
    "        #chatGPT_answer = rag_chain_ChatGPT.invoke(question)\n",
    "        chatGPT_answer = ''\n",
    "        chat_gpt_time = round(time.time() - start_time,2)\n",
    "\n",
    "        start_time = time.time()\n",
    "        Local_LLAMA_answer = rag_chain.invoke(question)\n",
    "        local_llama_time = round(time.time() - start_time,2)\n",
    "\n",
    "        print(f'Finished generating answer for question {count}.')\n",
    "        count+=1\n",
    "\n",
    "        # write the row to the CSV file\n",
    "        writer.writerow([question, answer, chatGPT_answer, Local_LLAMA_answer, chat_gpt_time, local_llama_time])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
