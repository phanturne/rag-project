{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from openai import OpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from llama_parse import LlamaParse\n",
    "import nest_asyncio\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import csv\n",
    "import time\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id cac11eca-64af-499e-9a19-d79d172426b2\n"
     ]
    }
   ],
   "source": [
    "# parse the document, save as a md file.\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "parser = LlamaParse(\n",
    "    #api_key=,  # can also be set in your env as LLAMA_CLOUD_API_KEY\n",
    "    result_type=\"markdown\",  # \"markdown\" and \"text\" are available\n",
    "    num_workers=4,  # if multiple files passed, split in `num_workers` API calls\n",
    "    verbose=True,\n",
    "    language=\"en\",  # Optionally you can define a language, default=en\n",
    ")\n",
    "\n",
    "# sync\n",
    "documents = parser.load_data(\"Orientation Documents-Spring 2024 Orientation Document.pdf\")\n",
    "documents\n",
    "\n",
    "# save the parsed data\n",
    "parse_path = \"parsed_data.md\"\n",
    "with open(parse_path, \"w\") as f:\n",
    "    f.write(documents[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the parsed data\n",
    "document_path = \"parsed_data.md\"\n",
    "loader = UnstructuredMarkdownLoader(document_path)\n",
    "loaded_documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the parse data into chunks, the chunk size is 512 characters\n",
    "# This parameter is very important, it will affect the performance of the model\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=20)\n",
    "splits = text_splitter.split_documents(loaded_documents)\n",
    "\n",
    "# Embed\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up prompt\n",
    "\n",
    "template = \"\"\"\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "local_prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The program mentioned in the context is a computer science program that requires students to be proficient in multiple programming languages such as C, Java, and Python. Additionally, students are expected to have knowledge in advanced topics like Advanced OS, Networking, Theory, and/or Algorithms. The program does not provide provisions for making up any deficiencies in these areas.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### RETRIEVAL and GENERATION using chatGPT 3.5 \n",
    "\n",
    "# Define the function to interact with the local LLM server\n",
    "def chatGPT_llm(prompt_text):\n",
    "    # Point to the local server\n",
    "    client = OpenAI()\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise. Don't state your role and task. Avoid using prefaces\"},\n",
    "        {\"role\": \"user\", \"content\": str(prompt_text)}\n",
    "    ],\n",
    "    temperature=0.8,\n",
    "    )\n",
    "    return str(completion.choices[0].message.content)\n",
    "\n",
    "# Update the chain to use the local LLM server\n",
    "rag_chain_ChatGPT = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | local_prompt\n",
    "    | chatGPT_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Question\n",
    "rag_chain_ChatGPT.invoke(\"What is this program?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This program appears to be a concentration or specialization program in a university or college, likely related to computer science or a related field. It requires students to have proficiency in multiple programming languages and advanced topics. The program is likely designed to help students focus their studies within a specific area.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### RETRIEVAL and GENERATION using Llama CPP###\n",
    "# The Llama model is hosted locally and can be accessed via the OpenAI API\n",
    "\n",
    "# Define the function to interact with the local LLM server\n",
    "def local_llm(prompt_text):\n",
    "    # Point to the local server\n",
    "    client = OpenAI(base_url=\"http://192.168.68.78:8080/v1\")\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"Meta-Llama-3-8B-Instruct-GGUF\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise. Don't state your role and task. Avoid using preface like According to the provided context.\"},\n",
    "        {\"role\": \"user\", \"content\": str(prompt_text)}\n",
    "    ],\n",
    "    temperature=0.8,\n",
    "    )\n",
    "    return str(completion.choices[0].message.content)\n",
    "\n",
    "# Update the chain to use the local LLM server\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | local_prompt\n",
    "    | local_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "llama_response = rag_chain.invoke(\"What is this program?\")\n",
    "llama_response[:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>qns_no</th>\n",
       "      <th>qns</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Student Onboarding/GT Email Account</td>\n",
       "      <td>1</td>\n",
       "      <td>Where do I send my official transcript(s) and ...</td>\n",
       "      <td>Send your final official transcript(s) and oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Student Onboarding/GT Email Account</td>\n",
       "      <td>2</td>\n",
       "      <td>What happens if I do not submit my official tr...</td>\n",
       "      <td>If you are a new student starting Spring 2024,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Student Onboarding/GT Email Account</td>\n",
       "      <td>3</td>\n",
       "      <td>Is there an orientation for the OMSCS program?</td>\n",
       "      <td>Since this is an online program, we do not hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Student Onboarding/GT Email Account</td>\n",
       "      <td>4</td>\n",
       "      <td>What are the expectations regarding my GT emai...</td>\n",
       "      <td>The Institute, as well as the department, will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Student Onboarding/GT Email Account</td>\n",
       "      <td>5</td>\n",
       "      <td>How can I access my GT email account?</td>\n",
       "      <td>Please visit this website for information on h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Graduation</td>\n",
       "      <td>13</td>\n",
       "      <td>Is it possible to graduate with honors/distinc...</td>\n",
       "      <td>Graduating with distinction/honors is not avai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Graduation</td>\n",
       "      <td>14</td>\n",
       "      <td>Can I continue taking OMSCS courses after I gr...</td>\n",
       "      <td>It is possible for students to continue taking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Graduation</td>\n",
       "      <td>15</td>\n",
       "      <td>Can I continue being a TA after I graduate fro...</td>\n",
       "      <td>This is possible, but it is more complicated t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Graduation</td>\n",
       "      <td>16</td>\n",
       "      <td>What technology-related services will I retain...</td>\n",
       "      <td>Please visit https://gatech.service-now.com/ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Graduation</td>\n",
       "      <td>17</td>\n",
       "      <td>How can I request a degree verification from t...</td>\n",
       "      <td>Please visit the Registrar’s website for infor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    category  qns_no  \\\n",
       "0    New Student Onboarding/GT Email Account       1   \n",
       "1    New Student Onboarding/GT Email Account       2   \n",
       "2    New Student Onboarding/GT Email Account       3   \n",
       "3    New Student Onboarding/GT Email Account       4   \n",
       "4    New Student Onboarding/GT Email Account       5   \n",
       "..                                       ...     ...   \n",
       "153                               Graduation      13   \n",
       "154                               Graduation      14   \n",
       "155                               Graduation      15   \n",
       "156                               Graduation      16   \n",
       "157                               Graduation      17   \n",
       "\n",
       "                                                   qns  \\\n",
       "0    Where do I send my official transcript(s) and ...   \n",
       "1    What happens if I do not submit my official tr...   \n",
       "2       Is there an orientation for the OMSCS program?   \n",
       "3    What are the expectations regarding my GT emai...   \n",
       "4                How can I access my GT email account?   \n",
       "..                                                 ...   \n",
       "153  Is it possible to graduate with honors/distinc...   \n",
       "154  Can I continue taking OMSCS courses after I gr...   \n",
       "155  Can I continue being a TA after I graduate fro...   \n",
       "156  What technology-related services will I retain...   \n",
       "157  How can I request a degree verification from t...   \n",
       "\n",
       "                                                   ans  \n",
       "0    Send your final official transcript(s) and oth...  \n",
       "1    If you are a new student starting Spring 2024,...  \n",
       "2    Since this is an online program, we do not hav...  \n",
       "3    The Institute, as well as the department, will...  \n",
       "4    Please visit this website for information on h...  \n",
       "..                                                 ...  \n",
       "153  Graduating with distinction/honors is not avai...  \n",
       "154  It is possible for students to continue taking...  \n",
       "155  This is possible, but it is more complicated t...  \n",
       "156  Please visit https://gatech.service-now.com/ho...  \n",
       "157  Please visit the Registrar’s website for infor...  \n",
       "\n",
       "[158 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load evaluation questions\n",
    "questions = pd.read_csv(\"faq_output.csv\")\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Is it possible to “start over” or “erase” my previous academic history?', 'answer': 'Unfortunately, this is not possible. Your previous academic history always will be a part of your student\\nrecord, even if you take time off and seek readmission into the program at a later time.\\nClick here to return to Table of Contents\\n25'}\n"
     ]
    }
   ],
   "source": [
    "# This is a random question generator\n",
    "def get_sample_questions():\n",
    "    random_question = questions.sample().iloc[0]\n",
    "    return {'question':random_question.qns, 'answer':random_question.ans}\n",
    "\n",
    "print(get_sample_questions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question is: I deferred my admission (or I am planning to defer my admission) and received a message indicating that my accounts are being inactivated. Can they remain active even though I am not a currently-enrolled\n",
      "student since I plan to enroll in a future term?\n",
      "\n",
      "chatGPT answer: If you defer your admission and receive a message about your accounts being inactivated, they will typically remain inactive until you are eligible to enroll again. Your accounts would regain access as the semester you plan to enroll in approaches, such as in the example of deferring admission from Spring 2024 to Fall 2024. During the period of deferral, while not currently enrolled, student-related services are usually discontinued until you are eligible to enroll.\n",
      "Time to invoke chatGPT: 1.55 seconds\n",
      "\n",
      "Local LLAMA answer: It seems that the accounts are being inactivated because you are not a currently-enrolled student, and student-related services are discontinued for students who are not eligible to enroll. However, it is mentioned that you would regain access to your accounts as the future semester approaches.<|eot_id|>\n",
      "Time to invoke local LLAMA: 2.61 seconds\n",
      "\n",
      "The official answer is: If you are not enrolled and are not classified as a student who is eligible to enroll, your student-related services\n",
      "will be discontinued. It is our understanding that OIT will not extend these student-related services until you are\n",
      "eligible to enroll. For example, if you were admitted for Spring 2024 but deferred your admission to Fall 2024, you\n",
      "would not have access to your accounts during the Spring 2024 semester but would regain access as the Fall\n",
      "2024 semester approached.\n"
     ]
    }
   ],
   "source": [
    "# Get sample questions and invoke the chains once\n",
    "\n",
    "start_time = time.time()\n",
    "q_and_a = get_sample_questions()\n",
    "print('The question is:', q_and_a.get('question'))\n",
    "print()\n",
    "\n",
    "# Invoke chatGPT\n",
    "start_time = time.time()\n",
    "print('chatGPT answer:', rag_chain_ChatGPT.invoke(q_and_a.get('question')))\n",
    "print('Time to invoke chatGPT:', round(time.time() - start_time,2),'seconds')\n",
    "print()\n",
    "\n",
    "# Invoke local LLAMA\n",
    "start_time = time.time()\n",
    "print('Local LLAMA answer:', rag_chain.invoke(q_and_a.get('question')))\n",
    "print('Time to invoke local LLAMA:', round(time.time() - start_time,2),'seconds')\n",
    "print()\n",
    "\n",
    "print('The official answer is:', q_and_a.get('answer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating answer for question 0.\n",
      "Finished generating answer for question 1.\n",
      "Finished generating answer for question 2.\n",
      "Finished generating answer for question 3.\n",
      "Finished generating answer for question 4.\n",
      "Finished generating answer for question 5.\n",
      "Finished generating answer for question 6.\n",
      "Finished generating answer for question 7.\n",
      "Finished generating answer for question 8.\n",
      "Finished generating answer for question 9.\n",
      "Finished generating answer for question 10.\n",
      "Finished generating answer for question 11.\n",
      "Finished generating answer for question 12.\n",
      "Finished generating answer for question 13.\n",
      "Finished generating answer for question 14.\n",
      "Finished generating answer for question 15.\n",
      "Finished generating answer for question 16.\n",
      "Finished generating answer for question 17.\n",
      "Finished generating answer for question 18.\n",
      "Finished generating answer for question 19.\n",
      "Finished generating answer for question 20.\n",
      "Finished generating answer for question 21.\n",
      "Finished generating answer for question 22.\n",
      "Finished generating answer for question 23.\n",
      "Finished generating answer for question 24.\n",
      "Finished generating answer for question 25.\n",
      "Finished generating answer for question 26.\n",
      "Finished generating answer for question 27.\n",
      "Finished generating answer for question 28.\n",
      "Finished generating answer for question 29.\n",
      "Finished generating answer for question 30.\n",
      "Finished generating answer for question 31.\n",
      "Finished generating answer for question 32.\n",
      "Finished generating answer for question 33.\n",
      "Finished generating answer for question 34.\n",
      "Finished generating answer for question 35.\n",
      "Finished generating answer for question 36.\n",
      "Finished generating answer for question 37.\n",
      "Finished generating answer for question 38.\n",
      "Finished generating answer for question 39.\n",
      "Finished generating answer for question 40.\n",
      "Finished generating answer for question 41.\n",
      "Finished generating answer for question 42.\n",
      "Finished generating answer for question 43.\n",
      "Finished generating answer for question 44.\n",
      "Finished generating answer for question 45.\n",
      "Finished generating answer for question 46.\n",
      "Finished generating answer for question 47.\n",
      "Finished generating answer for question 48.\n",
      "Finished generating answer for question 49.\n",
      "Finished generating answer for question 50.\n",
      "Finished generating answer for question 51.\n",
      "Finished generating answer for question 52.\n",
      "Finished generating answer for question 53.\n",
      "Finished generating answer for question 54.\n",
      "Finished generating answer for question 55.\n",
      "Finished generating answer for question 56.\n",
      "Finished generating answer for question 57.\n",
      "Finished generating answer for question 58.\n",
      "Finished generating answer for question 59.\n",
      "Finished generating answer for question 60.\n",
      "Finished generating answer for question 61.\n",
      "Finished generating answer for question 62.\n",
      "Finished generating answer for question 63.\n",
      "Finished generating answer for question 64.\n",
      "Finished generating answer for question 65.\n",
      "Finished generating answer for question 66.\n",
      "Finished generating answer for question 67.\n",
      "Finished generating answer for question 68.\n",
      "Finished generating answer for question 69.\n",
      "Finished generating answer for question 70.\n",
      "Finished generating answer for question 71.\n",
      "Finished generating answer for question 72.\n",
      "Finished generating answer for question 73.\n",
      "Finished generating answer for question 74.\n",
      "Finished generating answer for question 75.\n",
      "Finished generating answer for question 76.\n",
      "Finished generating answer for question 77.\n",
      "Finished generating answer for question 78.\n",
      "Finished generating answer for question 79.\n",
      "Finished generating answer for question 80.\n",
      "Finished generating answer for question 81.\n",
      "Finished generating answer for question 82.\n",
      "Finished generating answer for question 83.\n",
      "Finished generating answer for question 84.\n",
      "Finished generating answer for question 85.\n",
      "Finished generating answer for question 86.\n",
      "Finished generating answer for question 87.\n",
      "Finished generating answer for question 88.\n",
      "Finished generating answer for question 89.\n",
      "Finished generating answer for question 90.\n",
      "Finished generating answer for question 91.\n",
      "Finished generating answer for question 92.\n",
      "Finished generating answer for question 93.\n",
      "Finished generating answer for question 94.\n",
      "Finished generating answer for question 95.\n",
      "Finished generating answer for question 96.\n",
      "Finished generating answer for question 97.\n",
      "Finished generating answer for question 98.\n",
      "Finished generating answer for question 99.\n",
      "Finished generating answer for question 100.\n",
      "Finished generating answer for question 101.\n",
      "Finished generating answer for question 102.\n",
      "Finished generating answer for question 103.\n",
      "Finished generating answer for question 104.\n",
      "Finished generating answer for question 105.\n",
      "Finished generating answer for question 106.\n",
      "Finished generating answer for question 107.\n",
      "Finished generating answer for question 108.\n",
      "Finished generating answer for question 109.\n",
      "Finished generating answer for question 110.\n",
      "Finished generating answer for question 111.\n",
      "Finished generating answer for question 112.\n",
      "Finished generating answer for question 113.\n",
      "Finished generating answer for question 114.\n",
      "Finished generating answer for question 115.\n",
      "Finished generating answer for question 116.\n",
      "Finished generating answer for question 117.\n",
      "Finished generating answer for question 118.\n",
      "Finished generating answer for question 119.\n",
      "Finished generating answer for question 120.\n",
      "Finished generating answer for question 121.\n",
      "Finished generating answer for question 122.\n",
      "Finished generating answer for question 123.\n",
      "Finished generating answer for question 124.\n",
      "Finished generating answer for question 125.\n",
      "Finished generating answer for question 126.\n",
      "Finished generating answer for question 127.\n",
      "Finished generating answer for question 128.\n",
      "Finished generating answer for question 129.\n",
      "Finished generating answer for question 130.\n",
      "Finished generating answer for question 131.\n",
      "Finished generating answer for question 132.\n",
      "Finished generating answer for question 133.\n",
      "Finished generating answer for question 134.\n",
      "Finished generating answer for question 135.\n",
      "Finished generating answer for question 136.\n",
      "Finished generating answer for question 137.\n",
      "Finished generating answer for question 138.\n",
      "Finished generating answer for question 139.\n",
      "Finished generating answer for question 140.\n",
      "Finished generating answer for question 141.\n",
      "Finished generating answer for question 142.\n",
      "Finished generating answer for question 143.\n",
      "Finished generating answer for question 144.\n",
      "Finished generating answer for question 145.\n",
      "Finished generating answer for question 146.\n",
      "Finished generating answer for question 147.\n",
      "Finished generating answer for question 148.\n",
      "Finished generating answer for question 149.\n",
      "Finished generating answer for question 150.\n",
      "Finished generating answer for question 151.\n",
      "Finished generating answer for question 152.\n",
      "Finished generating answer for question 153.\n",
      "Finished generating answer for question 154.\n",
      "Finished generating answer for question 155.\n",
      "Finished generating answer for question 156.\n",
      "Finished generating answer for question 157.\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "with open('faq_output_with_answers_compare_new.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Question', 'Answer', 'chatGPT_answer', 'Local_LLAMA_answer','chat_gpt_time','local_llama_time'])\n",
    "\n",
    "    for row in questions.iterrows():\n",
    "        question = row[1].qns\n",
    "        answer = row[1].ans\n",
    "        start_time = time.time()\n",
    "        chatGPT_answer = rag_chain_ChatGPT.invoke(question)\n",
    "        chat_gpt_time = round(time.time() - start_time,2)\n",
    "\n",
    "        start_time = time.time()\n",
    "        Local_LLAMA_answer = rag_chain.invoke(question)\n",
    "        Local_LLAMA_answer = Local_LLAMA_answer[:-10]\n",
    "        local_llama_time = round(time.time() - start_time,2)\n",
    "\n",
    "        print(f'Finished generating answer for question {count}.')\n",
    "        count+=1\n",
    "\n",
    "        # write the row to the CSV file\n",
    "        writer.writerow([question, answer, chatGPT_answer, Local_LLAMA_answer, chat_gpt_time, local_llama_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
